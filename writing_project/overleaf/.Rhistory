Placeholder2[k]<-((r1[k] +1)/(1-r1[k]))*summary(lm(ysimwn[k,]~x))$coefficients[2,2]
b1[k]<-Placeholder1[k]
# You need to replace Placeholder1 with information from lm() note:: estimate of the slope!
#i don't see why we are correcting the se in the WN case
SE_corrected[k]<-(Placeholder2[k]) #You need to replace Placeholder2 with information from lm()
Pval_Corr[k]<-pt(abs(b1[k]/SE_corrected[k]),df=107,lower.tail=F)
}
wn.type1.lm <- length(which(Pval_t <= 0.05) == TRUE)/length(Pval_t)
wn.type1.adj <- length(which(Pval_Corr <= 0.05) == TRUE)/length(Pval_Corr)
## next up is ar1
## use ysimar1 from above
set.seed(13567)
x<-1901:2009
Sims<-1000
Pval_t<-Pval_Corr<-matrix(NA,nrow=Sims)
ysimar1<-replicate(Sims,arima.sim(n=109,model=list(ar=c(0.6)),sd=sqrt(0.03227)))
ysimar1 <- t(ysimar1)
#so 1000 rows and 109 columns
for (k in (1:Sims)){
Pval_t[k]<-summary(lm(ysimar1[k,]~x))$coef[2,4]#pull off the pvalue for the slope coefficient
r1[k]<-stats::acf(ysimar1[k,],plot=F)$acf[2]#calculate the adjustment
#pull off the next acf since I am using the stats package
Placeholder1[k]<-summary(lm(ysimar1[k,]~x))$coefficients[2,1]
Placeholder2[k]<-((r1[k] +1)/(1-r1[k]))*summary(lm(ysimar1[k,]~x))$coefficients[2,2]
b1[k]<-Placeholder1[k]
# You need to replace Placeholder1 with information from lm() note:: estimate of the slope!
#i don't see why we are correcting the se in the WN case
SE_corrected[k]<-(Placeholder2[k]) #You need to replace Placeholder2 with information from lm()
Pval_Corr[k]<-pt(abs(b1[k]/SE_corrected[k]),df=107,lower.tail=F)
}
ar1.type1.lm <- length(which(Pval_t <= 0.05) == TRUE)/length(Pval_t)
ar1.type1.adj <- length(which(Pval_Corr <= 0.05) == TRUE)/length(Pval_Corr)
## finally is ma1
## use ysimma1 from above
set.seed(13567)
x<-1901:2009
Sims<-1000
Pval_t<-Pval_Corr<-matrix(NA,nrow=Sims)
ysimma1<-replicate(Sims,arima.sim(n=109,list(ma=0.6),sd=sqrt(0.0007657007)))
ysimma1 <- t(ysimma1)
#so 1000 rows and 109 columns
for (k in (1:Sims)){
Pval_t[k]<-summary(lm(ysimma1[k,]~x))$coef[2,4]#pull off the pvalue for the slope coefficient
r1[k]<-stats::acf(ysimma1[k,],plot=F)$acf[2]#calculate the adjustment
#pull off the next acf since I am using the stats package
Placeholder1[k]<-summary(lm(ysimma1[k,]~x))$coefficients[2,1]
Placeholder2[k]<-((r1[k] +1)/(1-r1[k]))*summary(lm(ysimma1[k,]~x))$coefficients[2,2]
b1[k]<-Placeholder1[k]
# You need to replace Placeholder1 with information from lm() note:: estimate of the slope!
#i don't see why we are correcting the se in the WN case
SE_corrected[k]<-(Placeholder2[k]) #You need to replace Placeholder2 with information from lm()
Pval_Corr[k]<-pt(abs(b1[k]/SE_corrected[k]),df=107,lower.tail=F)
}
ma1.type1.lm <- length(which(Pval_t <= 0.05) == TRUE)/length(Pval_t)
ma1.type1.adj <- length(which(Pval_Corr <= 0.05) == TRUE)/length(Pval_Corr)
#You need to write two more similar loops and then calculate estimated Type I error rates
#I'm guessing the two other
tb.pvalues <- matrix(c(wn.type1.lm,wn.type1.adj,ar1.type1.lm,ar1.type1.adj,ma1.type1.lm,ma.type1.adj), nrow = 3,
ncol = 2, byrow = TRUE)
tb.pvalues <- matrix(c(wn.type1.lm,wn.type1.adj,ar1.type1.lm,ar1.type1.adj,ma1.type1.lm,ma1.type1.adj), nrow = 3,
ncol = 2, byrow = TRUE)
colnames(tb.pvalues) <- c("LM pvalue", "Adj. pvalue")
rownames(tb.pvalues) <- c("WN", "AR1", "MA1")
print(xtable(tb.pvalues, align = "||r|r|r||"))
install.packages("xtable")
library(xtable)
print(xtable(tb.pvalues, align = "||r|r|r||"))
tb.pvalues
print(xtable(tb.pvalues, align = "||r|r|r||", digits = 3))
var.ysimma1
set.seed(13567)
x<-1901:2009
Sims<-1000
Pval_t<-Pval_Corr<-matrix(NA,nrow=Sims)
ysimwn<-replicate(Sims,rnorm(n=109,sd=0.03227))
ysimwn <- t(ysimwn)
for (k in (1:Sims)){
Pval_t[k]<-summary(lm(ysimwn[k,]~x))$coef[2,4]#pull off the pvalue for the slope coefficient
r1[k]<-stats::acf(ysimwn[k,],plot=F)$acf[2]#calculate the adjustment
#pull off the next acf since I am using the stats package
Placeholder1[k]<-summary(lm(ysimwn[k,]~x))$coefficients[2,1]
Placeholder2[k]<-(sqrt(r1[k] +1)/(1-r1[k]))*summary(lm(ysimwn[k,]~x))$coefficients[2,2]
b1[k]<-Placeholder1[k]
# You need to replace Placeholder1 with information from lm() note:: estimate of the slope!
#i don't see why we are correcting the se in the WN case
SE_corrected[k]<-(Placeholder2[k]) #You need to replace Placeholder2 with information from lm()
Pval_Corr[k]<-pt(abs(b1[k]/SE_corrected[k]),df=107,lower.tail=F)
}
wn.type1.lm <- length(which(Pval_t <= 0.05) == TRUE)/length(Pval_t)
wn.type1.adj <- length(which(Pval_Corr <= 0.05) == TRUE)/length(Pval_Corr)
## next up is ar1
## use ysimar1 from above
set.seed(13567)
x<-1901:2009
Sims<-1000
Pval_t<-Pval_Corr<-matrix(NA,nrow=Sims)
ysimar1<-replicate(Sims,arima.sim(n=109,model=list(ar=c(0.6)),sd=sqrt(0.03227)))
ysimar1 <- t(ysimar1)
#so 1000 rows and 109 columns
for (k in (1:Sims)){
Pval_t[k]<-summary(lm(ysimar1[k,]~x))$coef[2,4]#pull off the pvalue for the slope coefficient
r1[k]<-stats::acf(ysimar1[k,],plot=F)$acf[2]#calculate the adjustment
#pull off the next acf since I am using the stats package
Placeholder1[k]<-summary(lm(ysimar1[k,]~x))$coefficients[2,1]
Placeholder2[k]<-(sqrt(r1[k] +1)/(1-r1[k]))*summary(lm(ysimar1[k,]~x))$coefficients[2,2]
b1[k]<-Placeholder1[k]
# You need to replace Placeholder1 with information from lm() note:: estimate of the slope!
#i don't see why we are correcting the se in the WN case
SE_corrected[k]<-(Placeholder2[k]) #You need to replace Placeholder2 with information from lm()
Pval_Corr[k]<-pt(abs(b1[k]/SE_corrected[k]),df=107,lower.tail=F)
}
ar1.type1.lm <- length(which(Pval_t <= 0.05) == TRUE)/length(Pval_t)
ar1.type1.adj <- length(which(Pval_Corr <= 0.05) == TRUE)/length(Pval_Corr)
## finally is ma1
## use ysimma1 from above
set.seed(13567)
x<-1901:2009
Sims<-1000
Pval_t<-Pval_Corr<-matrix(NA,nrow=Sims)
ysimma1<-replicate(Sims,arima.sim(n=109,list(ma=0.6),sd=sqrt(0.0007657007)))
ysimma1 <- t(ysimma1)
#so 1000 rows and 109 columns
for (k in (1:Sims)){
Pval_t[k]<-summary(lm(ysimma1[k,]~x))$coef[2,4]#pull off the pvalue for the slope coefficient
r1[k]<-stats::acf(ysimma1[k,],plot=F)$acf[2]#calculate the adjustment
#pull off the next acf since I am using the stats package
Placeholder1[k]<-summary(lm(ysimma1[k,]~x))$coefficients[2,1]
Placeholder2[k]<-(sqrt(r1[k] +1)/(1-r1[k]))*summary(lm(ysimma1[k,]~x))$coefficients[2,2]
b1[k]<-Placeholder1[k]
# You need to replace Placeholder1 with information from lm() note:: estimate of the slope!
#i don't see why we are correcting the se in the WN case
SE_corrected[k]<-(Placeholder2[k]) #You need to replace Placeholder2 with information from lm()
Pval_Corr[k]<-pt(abs(b1[k]/SE_corrected[k]),df=107,lower.tail=F)
}
ma1.type1.lm <- length(which(Pval_t <= 0.05) == TRUE)/length(Pval_t)
ma1.type1.adj <- length(which(Pval_Corr <= 0.05) == TRUE)/length(Pval_Corr)
#You need to write two more similar loops and then calculate estimated Type I error rates
#I'm guessing the two other
tb.pvalues <- matrix(c(wn.type1.lm,wn.type1.adj,ar1.type1.lm,ar1.type1.adj,ma1.type1.lm,ma1.type1.adj), nrow = 3,
ncol = 2, byrow = TRUE)
colnames(tb.pvalues) <- c("LM pvalue", "Adj. pvalue")
rownames(tb.pvalues) <- c("WN", "AR1", "MA1")
print(xtable(tb.pvalues, align = "||r|r|r||", digits = 3))
r1
summary(r1)
stats::acf(ysimwn[1,],plot=T)$acf[2]
weekdaystart <- Elec1$time.expanded[1]
Elec1$time.expanded <- as.factor(as.character(weekdays(
as.Date(Elec1$Time, origin = "2000-01-10"))))
Elec1$time.expanded <- substr(Elec1$time.expanded,1,7)
x.breaks <- c(seq(0,5520,by = 240))
h <- c(1:23)
day.names <- as.Date(h, origin = "2000-01-10")
day.names1 <- substr(day.names,6,10)
ggplot(data = Elec1, aes(x = time(time.expanded), y = Demand)) +
theme(axis.title.x = element_text(face="bold", colour="#990000", size=20),
axis.text.x  = element_text(angle=90, vjust=0.5, size=16)) +
geom_line() + scale_x_continuous("Day", breaks =
time(Elec1$time.expanded)[x.breaks], labels =
day.names1) +
ylab("total Watts consumed per 1000 people in 30 minutes") + theme_bw()
#the exact dates were too messy
Elec1$time.expanded
data(electricity) #Note: Day 0 = January 10, 2000 was a Monday, first observation at time 00:00=midnight
Elec1<-data.frame(Demand=as.vector(electricity[,1]),
Time=as.vector(electricity[,3]),Day=
floor(as.vector(electricity[,3])/48),DayofWeek=
c(rep(rep(0:6,each=48),16),rep(0:2,each=48))/7,
TimeofDay=as.vector(electricity[,4])/48)
Elec1$Dayfrac<-Elec1$Day+Elec1$TimeofDay
Elec1$DayofWeekF<-factor(Elec1$DayofWeek)
Elec1$TimeofDayF<-factor(Elec1$TimeofDay)
m1<-lm(Demand~Dayfrac+DayofWeekF+TimeofDayF,data=Elec1)
data(electricity) #Note: Day 0 = January 10, 2000 was a Monday, first observation at time 00:00=midnight
install.packages("TSA")
require(TSA)
data(electricity) #Note: Day 0 = January 10, 2000 was a Monday, first observation at time 00:00=midnight
Elec1<-data.frame(Demand=as.vector(electricity[,1]),
Time=as.vector(electricity[,3]),Day=
floor(as.vector(electricity[,3])/48),DayofWeek=
c(rep(rep(0:6,each=48),16),rep(0:2,each=48))/7,
TimeofDay=as.vector(electricity[,4])/48)
Elec1 <- NULL
Elec1<-data.frame(Demand=as.vector(electricity[,1]),
Time=as.vector(electricity[,3]),Day=
floor(as.vector(electricity[,3])/48),DayofWeek=
c(rep(rep(0:6,each=48),16),rep(0:2,each=48))/7,
TimeofDay=as.vector(electricity[,4])/48)
source('~/.active-rstudio-document', echo=TRUE)
trt <- c(rep(0,length(y_margin)))
for(i in 1:length(y_margin)){
trt[i] <- fn_error(y_margin[i])
}
length(y_margin)
fn_error(y_marin[1])
fn_error(y_margin[1])
y_margin[1]
source('~/.active-rstudio-document', echo=TRUE)
ss_trt
sse
ss_tot
ss_tot <- 5185.5-(375^2)/60
ss_trt <- (50^2 + 75^2 + 100^2 + 90^2 + 60^2)/6 - (375^2)/60
sse <- ss_tot-ss_trt
ss_tot
ss_trt
sse
ss_tot/59
ss_trt/4
sse/55
665.8/48.2
3.9/48.2
665.8/3.9
656.8/3.9
?pf
pf(0.01,4,15)
pf(0.99,4,15)
pf(0.99,15,4)
qf(0.99,15,4)
qf(0.95,15,4)
qf(0.90,15,4)
d20 <- c(24,28,37,30)
d30 <- c(37,44,34,35)
d40 <- c(42,47,52,38)
mu_hat <- mean(d20,d30,d40)
d20_mean <- mean(d20)
d30_mean <- mean(d30)
d40_mean <- mean(d40)
mu_hat <- mean(c(d20,d30,d40))
d20_mean <- mean(d20)
d30_mean <- mean(d30)
d40_mean <- mean(d40)
mu_hat
d20_mean
d30_mean
d40_mean
4*(mu_hat+d20_mean)
4*(d20_mean)
4*(d30_mean)
4*(d40_mean)
qf(0.99,15,4)
29.75-37.3
44.75-37.3
37.3+7.45
37.5+7.47
2*7.45 + 7.55 - 0.2
2*7.47 + 7.53 - 37.5
3*(-7.55) - 2*0.2 -7.45
3*(-7.53) - 2*37.5 - 7.43
37.3 - 7.55 + 0.2 +7.45
37.5 - 7.53 + 37.5 + 7.47
44.75-37.3
44.75-37.5
29.75-37.5
2*7.25 + 7.75 - 37.5
37.5+7.75
37.5+7.25
3*(-7.75) - 2*37.5 - 7.25
37.5 - 7.75 + 37.5 + 7.25
ovens <- data.frame(rbind(o1,o2,o3))
o1 <- c(491.5,498.3, 498.1, 493.5,493.6)
o2 <- c(488.5, 484.65, 497.9, 477.35)
o3 <- c(490.1, 484.8, 488.25, 473, 471.85, 478.65)
ovens <- data.frame(rbind(o1,o2,o3))
ovens <- data.frame(c(o1,o2,o3))
colnames(ovens) <- oven
colnames(ovens) <- "oven"
colnames(ovens) <- "temp"
ovens$oven <- c(rep(o1,length(o1)), rep(o2, length(o2)), rep(o3, length(o3)))
ovens$oven <- c(c(rep(o1,length(o1))), c(rep(o2, length(o2))), c(rep(o3, length(o3))))
ovens
length(o1)
length(o2)
length(o3)
ovens$oven <- c(c(rep(o1,length(o1))), c(rep(o2, length(o2))), c(rep(o3, length(o3))))
colnames(ovens)
dim(ovens)
o1 <- c(491.5,498.3, 498.1, 493.5,493.6)
o2 <- c(488.5, 484.65, 497.9, 477.35)
o3 <- c(490.1, 484.8, 488.25, 473, 471.85, 478.65)
oven <- c(c(rep(o1,length(o1))), c(rep(o2, length(o2))), c(rep(o3, length(o3))))
ovens <- data.frame(cbind(c(o1,o2,o3), oven))
colnames(ovens) <- c("temp", "oven")
oven
oven <- c(c(rep("o1",length(o1))), c(rep("o2", length(o2))), c(rep("o3", length(o3))))
ovens <- data.frame(cbind(c(o1,o2,o3), oven))
colnames(ovens) <- c("temp", "oven")
lm_oven <- lm(temp ~ as.factor(oven), data = ovens)
str(ovens)
lm_oven <- lm(as.numeric(as.character(temp)) ~ as.factor(oven), data = ovens)
anova(lm_oven)
Anova(lm_oven), type = "II")
Anova(lm_oven, type = "II")
require(car)
Anova(lm_oven, type = "II")
anova(lm_oven)
Anova(lm_oven, type = "III")
8.75+2.05+13.45
8.75-2.05
mean(o1)
length(o1)
mean(o2)
length(o2)
mean(o3)
length(o3)
d20 <- c(28,37,30)
d30 <- c(37,44,34,35)
d40 <- c(42,47,52,38)
sum(c(d20,d30,d40))/11
mean(d20)
mean(d30)
mean(d40)
d_tot <- sum(c(d20,d30,d40))/11
d20_mean <- mean(d20)
d30_mean <- mean(d30)
d40_mean <- mean(d40)
d_mean <- sum(c(d20,d30,d40))/11
d20_mean - d_mean
d20_mean - d_mean
d30_mean - d_mean
d40_mean - d_mean
sum(d20)
sum(d30)
sum(d40)
?variog
require(geoR)
?variog
require(geoR)
se <- read.csv("SEDataForAnalysisSpSurveyFinal.csv")
setwd("~/Documents/alm0823_hub/writing_project_s17/writing_project/overleaf")
se <- read.csv("SEDataForAnalysisSpSurveyFinal.csv")
head(se)
se.cols <- c("siteID", "xcoord", "ycoord", "mdcaty.x", "Date_", "Acres", "Hectares",
"SeSed", "SeRoots", "SeWater", "SeBugs")
se_sub <- se[,se.cols]
#rep.data.action = "first" keeps only first coordinate pair if same coordinate
#pair represented more than once in dataframe
se_geo <- as.geodata(obj = se_sub, coords.col = c(2,3),
data.col = c(8:11), covar.col = c(1,4,5,6,7),
na.action = "none")
summary(se_geo)
#diff number of NAs in each group
plot(se_geo, col.data = 1)
#won't work bc of all the NAs
geo_all <- as.geodata(obj = se_sub, coords.col = c(2,3),
data.col = c(8,9,10,11),
covar.col = c(1,4,5,6,7),
na.action = "none")
#I don't know what the colors mean...
#documentation says they are the four "Quartiles"
#do they mean the four quantiles?
#quantiles of what?
#I am thinking of the coordinates?
## need to figure out how to do this with all data
plot(geo_all, na.rm = TRUE)
#showing higher se concentration
sed_geo <- as.geodata(obj = se_sub, coords.col = c(2,3),
data.col = c(8),
covar.col = c(1,4,5,6,7),
na.action = "ifdata")
plot(sed_geo)
points(sed_geo, pt.divide = "rank.prop")
#shows it more clearly
## continuing from
## http://www.leg.ufpr.br/geoR/geoRdoc/vignette/geoRintro/geoRintrose3.html
## eda plots
# variogram with classical estimator
# switch to modulus estimator by estimator.type = "modulus"
sed_cloud <- variog(sed_geo, option = "cloud")
sed_bin <- variog(sed_geo, uvec = "default")
par(mfrow=c(1,2))
plot(sed_cloud, main = "Cloud Variogram")
plot(sed_bin, main = "Binned Variogram")
# create a "binned" cloud variogram
sed_cloudbin <- variog(sed_geo, uvec = "default",
bin.cloud = TRUE)
plot(sed_cloudbin, bin.cloud = T, main =
"Classical Estimator, Binned Cloud Variogram")
## directional variograms, angles = 0,45,90,135
## tolerance at default of 22.5 degrees
## resource on interpretting variogram and quality measures
par(mfrow=c(1,1))
sed_vario4 <- variog4(sed_geo)
plot(sed_vario4)
## parameter estimation
## theoretical vs. empirical
plot(sed_bin)
lines.variomodel(cov.model = "exp", cov.pars = c(1,2),
nugget = 4)
sed_smooth <- variog(sed_geo, option = "smooth")#, ksmooth = "normal")
lines(sed_smooth, type = "l", lty = 2)
legend(0.4,0.3,c("empirical", "exponential model",
"smoothed"), lty = c(1,1,2), lwd = c(1,3,1))
plot(variog(sed_geo, max.dist = 1))
lines.variomodel(cov.model = "exp", cov.pars = c(1,
0.3), nug = 0, max.dist = 1)
lines.variomodel(cov.model = "exp", cov.pars = c(1,
0.3), nug = 0, max.dist = 1)
plot(variog(sed_geo, max.dist = 1))
lines.variomodel(cov.model = "exp", cov.pars = c(1,
0.3), nug = 0, max.dist = 1)
lines.variomodel(cov.model = "mat", cov.pars = c(0.85,
0.2), nug = 0.1, kappa = 1, max.dist = 1,
lty = 2)
lines.variomodel(cov.model = "sph", cov.pars = c(0.8,
0.8), nug = 0.1, max.dist = 1, lwd = 2)
#ml or reml parameter estimation for
#gaussian random fields
sed_ml <- likfit(sed_geo, ini.cov.pars = c(1,1))
summary(sed_ml)
# no nugget
options(geoR.messages = FALSE)
sed_ml <- likfit(sed_geo, ini = c(1,0.5),
fix.nugget = T)
sed_reml <- likfit(sed_geo, ini = c(1,0.5),
fix.nugget = T,
method = "RML")
sed_ols <- variofit(sed_bin, ini = c(1,0.5),
fix.nugget = T, weights = "equal")
# fixed nugget
sed_ml.fn <- likfit(sed_geo,
sed_ml <- likfit(sed_geo, ini = c(1,0.5),
fix.nugget = T)
sed_reml <- likfit(sed_geo, ini = c(1,0.5),
sed_ols <- variofit(sed_bin, ini = c(1,0.5),
fix.nugget = T, weights = "equal")
sed_ml.fn <- likfit(sed_geo,
ini=c(1,0.5), fix.nugget = T,
nugget = 0.15)
sed_reml.fn <- likfit(sed_geo, ini = c(1,0.5),
fix.nugget = T,
nugget = 0.15,
weights = "equal")
sed_reml.fn <- likfit(sed_geo, ini = c(1,0.5),
fix.nugget = T,
nugget = 0.15)
sed_ols.fn <- variofit(sed_bin, ini = c(1,0.5),
fix.nugget = T,
nugget = 1, weights = "equal")
sed_wls.fn <- variofit(sed_bin, ini = c(1,2),
fix.nugget = T, nugget = 1)
require(akima)
sed_wls.fn <- variofit(sed_bin, ini = c(1,2),
fix.nugget = T, nugget = 1)
contour(se$xcoord, se$ycoord, se$EvalSed)
require(nlme)
sed_complete <- data.frame(se[which(is.na(se$SeSed) == FALSE), ])
sed.fit1 <- gls(SeSed ~ mdcaty.x -1,#no intercept
data = sed_complete, na.action = "na.omit")#fit ols
plot(Variogram(sed.fit1, form = ~sed_complete$xcoord + sed_complete$ycoord))
#use random picks for range and nugget
sed.spher <- update(sed.fit1, corr = corSpher(c(50,0.1), form = ~ xcoord +
ycoord, nugget = TRUE))
sed.ratio <- update(sed.fit1, corr = corRatio(c(50,0.1), form = ~ xcoord +
ycoord, nugget = TRUE))
sed.lin <- update(sed.fit1, corr = corLin(c(50,0.1), form = ~ xcoord +
ycoord, nugget = TRUE))
sed.exp <- update(sed.fit1, corr = corExp(c(50,0.1), form = ~ xcoord +
ycoord, nugget = TRUE))
sed.gauss <- update(sed.fit1, corr = corGaus(c(50,0.1), form = ~ xcoord +
ycoord, nugget = TRUE))
anova(sed.fit1, sed.spher, sed.ratio, sed.lin, sed.exp, sed.gauss, test = FALSE)
sed.fit1 <- gls(SeSed ~ mdcaty.x, data = sed_complete,#, corr = corSpher)#,form = ~ xcoord + ycoord, nugget = FALSE,
na.action = "na.omit")#fit ols
########## section 4.2 kattegat salinity data #############
data("kattegat") #geodata object
# NAs are not allowed
summary(kattegat)
str(kattegat)
# from help examples
plot(c(550,770),c(6150,6420),type="n",xlab="X UTM",ylab="Y UTM")
points(kattegat, add=TRUE)
lapply(kattegat$dk, lines, lwd=2)
## hmm can't figure this out for se data
minx_se <- min(se$xcoord)
maxx_se <- max(se$xcoord)
miny_se <- min(se$ycoord)
maxy_se <- max(se$ycoord)
plot(c(minx_se, maxx_se),c(minx_se,maxx_se),type="n",xlab="X Coord",ylab="Y Coord")
points(se_geo, add = TRUE)
lapply(se_geo$dk, lines, lwd = 2)
##############################################################
################### 4.2 trying to fit model ##################
##############################################################
# prior on phi
set.seed(53216)
phi <- c(seq(10, 100))
# find poster on phi -- discrete unif 10,100
# first need V,R,S
# need F == X matrix
# need R == correlation matrix, using exponential
names(kattegat)
require(stats)
katte_coords <- data.frame(cbind(kattegat$coords[,1], kattegat$coords[,2]))
fn_num <- function(x){
as.numeric(as.character(x))
}
katte_coords <- apply(katte_coords, 2, fn_num)
# pairwise euclidean distances
u <- as.matrix(dist(katte_coords, method = "euclidean", p = 2))
fn_pu <- function(x,y){
exp(-x/y)
}
R <- data.frame(matrix(vector(),70,70))
for(i in 1:70){
for(j in 1:70){
R[i,j] <- fn_pu(u[i,j],phi)
}
}
# I belive x1 and x2 in the model are the lat and long coords
# but don' tknow how to check
F <- data.frame(cbind(c(rep(1,70)), katte_coords))
